\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bbm}
\begin{document}
\section{SDP for two community}
\subsection{ADMM scheme}
Let $B_{ij} = 1$ if $(i,j) \in E(G)$ and $B_{ij} = -\kappa$ if $(i,j) \not \in E(G)$.
We require $0<\kappa \leq 1$. When $\kappa = 1$, the matrix $B$ is the same with
Abbe's formulation in \cite{abbe2015exact}.
To solve $\max Tr(BX)$ s.t. $X_{ii} = 1$ and $X \succeq 0$.
We use ADMM, that is, we solve
\begin{align*}
\min & - \langle B, X\rangle + \delta_{Z \succeq 0} + \delta_{L(X) = \mathbbm{1}_n}\\
s.t.& X=Z
\end{align*}
$L$ is a mapping from $\mathbb{R}^{n \times n} \to \mathbb{R}^n$ such that $[L(X)]_i =  \langle X,F_i \rangle $.
$F_i$ is a matrix with element $(i,i)$ equal to 1 and 0 elsewhere.
The projection $\Pi_{A}(Y)$ simply modifies the diagonal elements of $Y$ to $1$.
The scaled form of ADMM \cite{boyd2011distributed} is given by
\begin{align}
X^{k+1} = \Pi_A(Z^k - U^k + \frac{1}{\rho}B)\label{eq:admm} \\
Z^{k+1} = \Pi_{S_+^n}(X^{k+1} + U^{k}) \\
U^{k+1} = U^k + (X^{k+1} - Z^{k+1}) 
\end{align}
\begin{thebibliography}{9}
\bibitem{abbe2015exact}
Emmanuel Abbe, Afonso~S Bandeira, and Georgina Hall.
\newblock Exact recovery in the stochastic block model.
\newblock {\em IEEE Transactions on Information Theory}, 62(1):471--487, 2015.
\bibitem{boyd2011distributed}
Stephen Boyd, Neal Parikh, and Eric Chu.
\newblock {\em Distributed optimization and statistical learning via the
  alternating direction method of multipliers}.
\newblock Now Publishers Inc, 2011.
\end{thebibliography}
\end{document}


